{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4822a8-1687-4931-abe7-964bcbcbe468",
   "metadata": {
    "tags": []
   },
   "source": [
    "The below cells of code are used to create a Logistic Regression model to predict if a flight out of an aiport with the US will be delayed or not. The first cell of code imports needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8d9b3f-d1ef-4700-9839-10ede48e17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41957992-6853-46ac-8d43-d305afb4cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/allen/Desktop/MSDS/ML1/archive/airline_merged.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54cd49-65bb-4da1-a6eb-490dba1c5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b0924-0abe-4e64-a918-58c791aa31f1",
   "metadata": {},
   "source": [
    "After importing the merged file, airline_merged.csv, that was created in the ipynb file, airline_files_merge, we needed to remove the addditional column(Unnamed: 0) that is added in the export. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1c11cd-01fe-45ba-8c38-cc2377490bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline_cd</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>airport_origin</th>\n",
       "      <th>...</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>Alaska Airlines Inc.</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>811.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>Alaska Airlines Inc.</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819074</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>688</td>\n",
       "      <td>N657JB</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>753.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819075</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>745</td>\n",
       "      <td>N828JB</td>\n",
       "      <td>JFK</td>\n",
       "      <td>John F. Kennedy International AirportÂ (New Yor...</td>\n",
       "      <td>...</td>\n",
       "      <td>430.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819076</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>1503</td>\n",
       "      <td>N913JB</td>\n",
       "      <td>JFK</td>\n",
       "      <td>John F. Kennedy International AirportÂ (New Yor...</td>\n",
       "      <td>...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819077</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>333</td>\n",
       "      <td>N527JB</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819078</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>839</td>\n",
       "      <td>N534JB</td>\n",
       "      <td>JFK</td>\n",
       "      <td>John F. Kennedy International AirportÂ (New Yor...</td>\n",
       "      <td>...</td>\n",
       "      <td>442.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5819079 rows Ã 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  month  day  day_of_week airline_cd            airline_name  \\\n",
       "0        2015      1    1            4         AS    Alaska Airlines Inc.   \n",
       "1        2015      1    1            4         AA  American Airlines Inc.   \n",
       "2        2015      1    1            4         US         US Airways Inc.   \n",
       "3        2015      1    1            4         AA  American Airlines Inc.   \n",
       "4        2015      1    1            4         AS    Alaska Airlines Inc.   \n",
       "...       ...    ...  ...          ...        ...                     ...   \n",
       "5819074  2015     12   31            4         B6         JetBlue Airways   \n",
       "5819075  2015     12   31            4         B6         JetBlue Airways   \n",
       "5819076  2015     12   31            4         B6         JetBlue Airways   \n",
       "5819077  2015     12   31            4         B6         JetBlue Airways   \n",
       "5819078  2015     12   31            4         B6         JetBlue Airways   \n",
       "\n",
       "         flight_number tail_number origin_airport  \\\n",
       "0                   98      N407AS            ANC   \n",
       "1                 2336      N3KUAA            LAX   \n",
       "2                  840      N171US            SFO   \n",
       "3                  258      N3HYAA            LAX   \n",
       "4                  135      N527AS            SEA   \n",
       "...                ...         ...            ...   \n",
       "5819074            688      N657JB            LAX   \n",
       "5819075            745      N828JB            JFK   \n",
       "5819076           1503      N913JB            JFK   \n",
       "5819077            333      N527JB            MCO   \n",
       "5819078            839      N534JB            JFK   \n",
       "\n",
       "                                            airport_origin  ... arrival_time  \\\n",
       "0              Ted Stevens Anchorage International Airport  ...        408.0   \n",
       "1                        Los Angeles International Airport  ...        741.0   \n",
       "2                      San Francisco International Airport  ...        811.0   \n",
       "3                        Los Angeles International Airport  ...        756.0   \n",
       "4                     Seattle-Tacoma International Airport  ...        259.0   \n",
       "...                                                    ...  ...          ...   \n",
       "5819074                  Los Angeles International Airport  ...        753.0   \n",
       "5819075  John F. Kennedy International AirportÂ (New Yor...  ...        430.0   \n",
       "5819076  John F. Kennedy International AirportÂ (New Yor...  ...        432.0   \n",
       "5819077                      Orlando International Airport  ...        330.0   \n",
       "5819078  John F. Kennedy International AirportÂ (New Yor...  ...        442.0   \n",
       "\n",
       "        arrival_delay diverted  cancelled  cancellation_reason  \\\n",
       "0               -22.0        0          0                  NaN   \n",
       "1                -9.0        0          0                  NaN   \n",
       "2                 5.0        0          0                  NaN   \n",
       "3                -9.0        0          0                  NaN   \n",
       "4               -21.0        0          0                  NaN   \n",
       "...               ...      ...        ...                  ...   \n",
       "5819074         -26.0        0          0                  NaN   \n",
       "5819075         -16.0        0          0                  NaN   \n",
       "5819076          -8.0        0          0                  NaN   \n",
       "5819077         -10.0        0          0                  NaN   \n",
       "5819078           2.0        0          0                  NaN   \n",
       "\n",
       "        air_system_delay security_delay airline_delay late_aircraft_delay  \\\n",
       "0                    NaN            NaN           NaN                 NaN   \n",
       "1                    NaN            NaN           NaN                 NaN   \n",
       "2                    NaN            NaN           NaN                 NaN   \n",
       "3                    NaN            NaN           NaN                 NaN   \n",
       "4                    NaN            NaN           NaN                 NaN   \n",
       "...                  ...            ...           ...                 ...   \n",
       "5819074              NaN            NaN           NaN                 NaN   \n",
       "5819075              NaN            NaN           NaN                 NaN   \n",
       "5819076              NaN            NaN           NaN                 NaN   \n",
       "5819077              NaN            NaN           NaN                 NaN   \n",
       "5819078              NaN            NaN           NaN                 NaN   \n",
       "\n",
       "        weather_delay  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "5819074           NaN  \n",
       "5819075           NaN  \n",
       "5819076           NaN  \n",
       "5819077           NaN  \n",
       "5819078           NaN  \n",
       "\n",
       "[5819079 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unwanted column from previous export\n",
    "df.drop(columns =['Unnamed: 0'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003edab6-f19a-4a28-9191-15ca78f7b4b3",
   "metadata": {},
   "source": [
    "The below cell creates a correlation matrix using all of the numerical columns and removes any column that has a correlation coeffecient that is greater than 0.90. This will eventually help decrease the amount of columns that are used in the model and help with any assumptions that need to be met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c6aa9e-61b0-4d87-9822-180d5faf4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/_lgzxbk177j14_b82nbl10br0000gn/T/ipykernel_7999/4014107192.py:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    }
   ],
   "source": [
    "#dropping highly correlated columns\n",
    "#https://www.codegrepper.com/code-examples/python/how+to+drop+highly+correlated+features\n",
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "df = df.drop(columns = to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca28135-23ba-49b4-a3b3-c0d0c301317a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline_cd</th>\n",
       "      <th>airline_name</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>airport_origin</th>\n",
       "      <th>...</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_reason</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>Alaska Airlines Inc.</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>Alaska Airlines Inc.</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  year  day  day_of_week airline_cd            airline_name  \\\n",
       "0           0  2015    1            4         AS    Alaska Airlines Inc.   \n",
       "1           1  2015    1            4         AA  American Airlines Inc.   \n",
       "2           2  2015    1            4         US         US Airways Inc.   \n",
       "3           3  2015    1            4         AA  American Airlines Inc.   \n",
       "4           4  2015    1            4         AS    Alaska Airlines Inc.   \n",
       "\n",
       "   flight_number tail_number origin_airport  \\\n",
       "0             98      N407AS            ANC   \n",
       "1           2336      N3KUAA            LAX   \n",
       "2            840      N171US            SFO   \n",
       "3            258      N3HYAA            LAX   \n",
       "4            135      N527AS            SEA   \n",
       "\n",
       "                                airport_origin  ... taxi_in scheduled_arrival  \\\n",
       "0  Ted Stevens Anchorage International Airport  ...     4.0               430   \n",
       "1            Los Angeles International Airport  ...     4.0               750   \n",
       "2          San Francisco International Airport  ...    11.0               806   \n",
       "3            Los Angeles International Airport  ...     8.0               805   \n",
       "4         Seattle-Tacoma International Airport  ...     5.0               320   \n",
       "\n",
       "  diverted  cancelled cancellation_reason air_system_delay security_delay  \\\n",
       "0        0          0                 NaN              NaN            NaN   \n",
       "1        0          0                 NaN              NaN            NaN   \n",
       "2        0          0                 NaN              NaN            NaN   \n",
       "3        0          0                 NaN              NaN            NaN   \n",
       "4        0          0                 NaN              NaN            NaN   \n",
       "\n",
       "  airline_delay late_aircraft_delay  weather_delay  \n",
       "0           NaN                 NaN            NaN  \n",
       "1           NaN                 NaN            NaN  \n",
       "2           NaN                 NaN            NaN  \n",
       "3           NaN                 NaN            NaN  \n",
       "4           NaN                 NaN            NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at dataframe after removing highly correlated fields.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751ac87-4f1a-4a33-a7f6-41fef05a5328",
   "metadata": {},
   "source": [
    "Since the data set is quite large and personal laptops will struggle to churn through the amount of rows and columns, we decided to filter down the data to Dallas-Fort Worth International Airport. This decreased the data frame size from almost 6 million rows to just under 240k rows and also helped with the one hot encoding below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab215088-7f4a-45d0-a590-d5ac39b00478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting 5 busiest airports in US\n",
    "#airports = ['ATL','DFW','ORD','LAX','DEN']\n",
    "airports = ['DFW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cbd612c-82e1-49b6-ac06-68850cb5bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air = df.loc[df['origin_airport'].isin(airports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6eac4a2-5150-4694-8d3b-d421764b6df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>latitude_origin</th>\n",
       "      <th>latitude_destination</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>...</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>diverted</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_system_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.395510e+05</td>\n",
       "      <td>239551.0</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>233658.000000</td>\n",
       "      <td>233383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>233177.000000</td>\n",
       "      <td>233177.000000</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>239551.000000</td>\n",
       "      <td>50478.000000</td>\n",
       "      <td>50478.000000</td>\n",
       "      <td>50478.000000</td>\n",
       "      <td>50478.000000</td>\n",
       "      <td>50478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.683140e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>15.644890</td>\n",
       "      <td>3.945598</td>\n",
       "      <td>1999.527111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1406.443325</td>\n",
       "      <td>11.528820</td>\n",
       "      <td>17.242344</td>\n",
       "      <td>...</td>\n",
       "      <td>1556.667347</td>\n",
       "      <td>6.466109</td>\n",
       "      <td>1579.647649</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>10.543623</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>21.174888</td>\n",
       "      <td>20.654245</td>\n",
       "      <td>5.074389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.672708e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.784501</td>\n",
       "      <td>1.996657</td>\n",
       "      <td>1155.423485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458.043842</td>\n",
       "      <td>36.308279</td>\n",
       "      <td>8.543331</td>\n",
       "      <td>...</td>\n",
       "      <td>507.568388</td>\n",
       "      <td>5.213076</td>\n",
       "      <td>487.907272</td>\n",
       "      <td>0.052020</td>\n",
       "      <td>0.159454</td>\n",
       "      <td>22.054115</td>\n",
       "      <td>2.274275</td>\n",
       "      <td>39.279341</td>\n",
       "      <td>39.726000</td>\n",
       "      <td>24.350348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.243666e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1155.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1206.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.577904e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2214.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1604.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.935769e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2810.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1820.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.819003e+06</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6529.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1377.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>2359.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>1331.000000</td>\n",
       "      <td>862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      year            day    day_of_week  flight_number  \\\n",
       "count  2.395510e+05  239551.0  239551.000000  239551.000000  239551.000000   \n",
       "mean   2.683140e+06    2015.0      15.644890       3.945598    1999.527111   \n",
       "std    1.672708e+06       0.0       8.784501       1.996657    1155.423485   \n",
       "min    7.000000e+01    2015.0       1.000000       1.000000       4.000000   \n",
       "25%    1.243666e+06    2015.0       8.000000       2.000000    1164.000000   \n",
       "50%    2.577904e+06    2015.0      16.000000       4.000000    2214.000000   \n",
       "75%    3.935769e+06    2015.0      23.000000       6.000000    2810.000000   \n",
       "max    5.819003e+06    2015.0      31.000000       7.000000    6529.000000   \n",
       "\n",
       "       latitude_origin  latitude_destination  scheduled_departure  \\\n",
       "count              0.0                   0.0        239551.000000   \n",
       "mean               NaN                   NaN          1406.443325   \n",
       "std                NaN                   NaN           458.043842   \n",
       "min                NaN                   NaN           140.000000   \n",
       "25%                NaN                   NaN          1025.000000   \n",
       "50%                NaN                   NaN          1400.000000   \n",
       "75%                NaN                   NaN          1820.000000   \n",
       "max                NaN                   NaN          2359.000000   \n",
       "\n",
       "       departure_delay       taxi_out  ...      wheels_on        taxi_in  \\\n",
       "count    233658.000000  233383.000000  ...  233177.000000  233177.000000   \n",
       "mean         11.528820      17.242344  ...    1556.667347       6.466109   \n",
       "std          36.308279       8.543331  ...     507.568388       5.213076   \n",
       "min         -28.000000       1.000000  ...       1.000000       1.000000   \n",
       "25%          -4.000000      13.000000  ...    1155.000000       4.000000   \n",
       "50%          -1.000000      15.000000  ...    1555.000000       5.000000   \n",
       "75%          11.000000      19.000000  ...    1950.000000       7.000000   \n",
       "max        1377.000000     225.000000  ...    2400.000000     197.000000   \n",
       "\n",
       "       scheduled_arrival       diverted      cancelled  air_system_delay  \\\n",
       "count      239551.000000  239551.000000  239551.000000      50478.000000   \n",
       "mean         1579.647649       0.002713       0.026107         10.543623   \n",
       "std           487.907272       0.052020       0.159454         22.054115   \n",
       "min             1.000000       0.000000       0.000000          0.000000   \n",
       "25%          1206.000000       0.000000       0.000000          0.000000   \n",
       "50%          1604.000000       0.000000       0.000000          0.000000   \n",
       "75%          1959.000000       0.000000       0.000000         15.000000   \n",
       "max          2359.000000       1.000000       1.000000        664.000000   \n",
       "\n",
       "       security_delay  airline_delay  late_aircraft_delay  weather_delay  \n",
       "count    50478.000000   50478.000000         50478.000000   50478.000000  \n",
       "mean         0.113000      21.174888            20.654245       5.074389  \n",
       "std          2.274275      39.279341            39.726000      24.350348  \n",
       "min          0.000000       0.000000             0.000000       0.000000  \n",
       "25%          0.000000       0.000000             0.000000       0.000000  \n",
       "50%          0.000000       7.000000             0.000000       0.000000  \n",
       "75%          0.000000      27.000000            26.000000       0.000000  \n",
       "max        190.000000     942.000000          1331.000000     862.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90086c9-7e2f-4819-8217-41f4324cd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting columns that are dtype != numeric\n",
    "non_numeric = df_air.select_dtypes(exclude = np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab5236-8d3b-4706-994a-5e29407b9dd0",
   "metadata": {},
   "source": [
    "Because we want to predict if an airplane is going to be delayed or not using logistic regression, we created a new field called \"is_delay\" from the \"departure_delay\" field. To do this, we created a function that we could pass a numeric field through and if the value for that row is greater than 0, we imputed \"1\" into the curated field to signifiy the flight was delayed. If the value was less than 0, we imputed \"0\" to signify that the flight was not delayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b0e4f3-6c7d-4621-bb21-1ee75156cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/_lgzxbk177j14_b82nbl10br0000gn/T/ipykernel_7999/3939397851.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_air['is_delay'] = df_air.loc[:,'departure_delay'].apply(is_delayed)\n"
     ]
    }
   ],
   "source": [
    "#create binary response for logistic regression\n",
    "# create a function\n",
    "def is_delayed(delay,axis=1):\n",
    "    if delay <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# create a new column based on condition\n",
    "df_air['is_delay'] = df_air.loc[:,'departure_delay'].apply(is_delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed7c27-40be-4042-a800-60a844715e64",
   "metadata": {},
   "source": [
    "After creating the \"is_delay\" field, we then began to One Hot Encode any categorial variables so that our model could interpret and use those columns. This caused a 250k by 42 data set to become 240k by 3400. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b521613-8e2c-488a-8ac4-4e8a38bae1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Departure Delay - response\n",
    "#altered from https://www.statology.org/one-hot-encoding-in-python/\n",
    "\n",
    "#creating instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on non-numeric column s\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(df_air[non_numeric]).toarray())\n",
    "\n",
    "#return column names from encoder\n",
    "encoder_df.columns = encoder.get_feature_names_out()\n",
    "\n",
    "#merge one-hot encoded columns back with original DataFrame\n",
    "encoded = df_air.join(encoder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191b5bfe-398c-4688-bdcc-f3c729ce2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop original columns\n",
    "final_df = encoded.drop(non_numeric, axis=1)\n",
    "\n",
    "#head(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c377fc-7ea9-4eae-87df-58b3eb375dfb",
   "metadata": {},
   "source": [
    "Once the target variable was created and we one hot encoded the data set, we were able to begin modeling our data. To start, we separated the features with the target varibale as to not leave the response in a test or train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de9e30a9-dd5a-4fe9-9316-bac97c77c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = final_df.loc[:, final_df.columns != 'is_delay'].columns\n",
    "X = final_df[feature_cols] # Features\n",
    "y = final_df.is_delay # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12292d53-3bca-4002-8156-b5c0167d0325",
   "metadata": {},
   "source": [
    "From sklearn, we used their train_test_split package to create a 75/25 train and test split for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173324c3-b94f-4b33-8d6a-35354e6beb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb8b48-8189-42ef-881c-b29fabf7e6a8",
   "metadata": {},
   "source": [
    "After one hot encoding, for our logistic regession model to run, we imputed the NaN values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86bcd21-2cdb-4569-913a-18212521de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing 0 into NaN values for logistic regression after OHE\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "y_test = y_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e481ec-0837-434b-aa2d-8fc0ca2f05de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (179663, 3395) \n",
      "\n",
      "X_test shape:  (59888, 3395) \n",
      "\n",
      "y_train shape:  (179663,) \n",
      "\n",
      "y_test shape:  (59888,)\n"
     ]
    }
   ],
   "source": [
    "#checking shape of data\n",
    "print('X_train shape: ',X_train.shape,'\\n')\n",
    "print('X_test shape: ',X_test.shape,'\\n')\n",
    "print('y_train shape: ',y_train.shape,'\\n')\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b587e3-e243-45e5-8a5a-2c259de9f41b",
   "metadata": {},
   "source": [
    "#CV implement::::\n",
    "#\n",
    "# Create an instance of StratifiedKFold which can be used to get indices of different training and test folds\n",
    "#\n",
    "strtfdKFold = StratifiedKFold(n_splits=10)\n",
    "kfold = strtfdKFold.split(X, y)\n",
    "scores = []\n",
    "#\n",
    "#\n",
    "#\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe.fit(X_train.iloc[train, :], y_train.iloc[train])\n",
    "    score = pipe.score(X_train.iloc[test, :], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Training/Test Split Distribution: %s, Accuracy: %.3f' % (k+1, np.bincount(y_train.iloc[train]), score))\n",
    " \n",
    "print('\\n\\nCross-Validation accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ada40f-1ec5-426a-b89c-f99ad3d5a0b0",
   "metadata": {},
   "source": [
    "To simplify the code and useability of the model, we used a pipeline function from sklearn to standardize (using StandarScaler), run the data through PCA and then finally a logistic regession model with a CV = 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e4a60c7-dc55-4d87-9dcd-4617066d367e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m logistic \u001b[38;5;241m=\u001b[39m LogisticRegressionCV(solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m,penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m,l1_ratios \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m )\n\u001b[1;32m     11\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, scaler), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m\"\u001b[39m, pca), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, logistic)])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:2046\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTolerance for stopping criteria must be positive; got (tol=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol\n\u001b[1;32m   2042\u001b[0m     )\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2044\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2045\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratios \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2046\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratios\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2047\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   2048\u001b[0m             (\n\u001b[1;32m   2049\u001b[0m                 \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l1_ratio, numbers\u001b[38;5;241m.\u001b[39mNumber)\n\u001b[1;32m   2050\u001b[0m                 \u001b[38;5;129;01mor\u001b[39;00m l1_ratio \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2051\u001b[0m                 \u001b[38;5;129;01mor\u001b[39;00m l1_ratio \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2052\u001b[0m             )\n\u001b[1;32m   2053\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m l1_ratio \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratios\n\u001b[1;32m   2054\u001b[0m         )\n\u001b[1;32m   2055\u001b[0m     ):\n\u001b[1;32m   2056\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2057\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratios must be a list of numbers between \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2058\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0 and 1; got (l1_ratios=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2059\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratios\n\u001b[1;32m   2060\u001b[0m         )\n\u001b[1;32m   2061\u001b[0m     l1_ratios_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratios\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/getting-the-most-out-of-scikit-learn-pipelines-c2afc4410f1a\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# Define a Standard Scaler to normalize inputs\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale -> PCA -> LR w/ CV=10\n",
    "logistic = LogisticRegressionCV(solver = 'saga',penalty='elasticnet',l1_ratios = 0.5,cv=10 )\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"logistic\", logistic)])\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85cccb-b58a-4a96-a30e-195bfdaee994",
   "metadata": {},
   "source": [
    "After fitting the model, we then ran our test data set through to create predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3995d9f-6318-45e0-b537-70a5a6630b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "y_pred=pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e947cd5-89b0-490a-86f3-b0c73c6e28c4",
   "metadata": {},
   "source": [
    "After creating predictions on our test data set, we pulled metrics to determine how well our model performed. Our base model had an accuracy of 78.38% with a precision of 96.08% and a recall of 51.54%. This model output gives us a good starting point for hypertuing the model and comparison against some more powerful models such as XGBoost or LightGBM. After computing these metrics we then created a confusion matrix heatmap to better visualize how well our model was predicting and where the model could perform better with False Positives and False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035cc4b-c3ac-4f0f-969f-1684f923801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe13d9-0b57-4c1b-bafc-901a2143b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation Matrix Heatmap\n",
    "# code from: https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83832926-42e8-4b05-b954-df47ce53ad2e",
   "metadata": {},
   "source": [
    "Finally we chose to plot a ROC curve to visualize specificity and sensitiviy of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3175cb-7b67-4af3-bc88-6224a2f17de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "y_pred_proba = pipe.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"Base Logistic Regression, auc= \"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
